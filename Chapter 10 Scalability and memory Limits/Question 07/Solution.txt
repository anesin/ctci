Assumptions

  • Other than calling out to processSearch as necessary, all query processing happens on the initial machine that was called.
  • The number of queries we wish to cache is large (millions).
  • Calling between machines is relatively quick.
  • The result for a given query is an ordered list of URLs, each of which has an associated 50 character title and 200 character summary.
  • The most popular queries are extremely popular, such that they would always appear in the cache.



System Requirements

  • Efficient lookups given a key.
  • Expiration of old data so that it can be replaced with new data.



Step 1: Design a Cache for a Single System

  • A linked list would allow easy purging of old data, by moving "fresh" items to the front. We could implement it to remove the last element of the linked list when the list exceeds a certain size.
  • A hash table allows efficient lookups of data, but it wouldn't ordinarily allow easy data purging.

For we get the best of both worlds, the two data structures are merged.



Step 2: Expand to Many Machines

  Option 1. Each machine has its own cache.
  Option 2. Each machine has a copy of the cache.
  Option 3. Each machine stores a segment of the cache.



Step 3: Updating results when contents change

The primary times would be when:
  1. The content at a URL changes (or the page at that URL is removed).
  2. The ordering of results change in response to the rank of a page changing.
  3. New pages appear related to a particular query.

To handle situations #1 and #2, we could create a separate hash table that would tell us which cached queries are tied to a specific URL. This could be handled completely separately from the other caches, and reside on different machines. However, this solution may require a lot of data.
Alternatively, if the data doesn't require instant refreshing (which it probably doesn't), we could periodically crawl through the cache stored on each machine to purge queries tied to the updated URLs.

A good way to handle Situation #3 (and likely something we'd want to do anyway) is to implement an "automatic time-out" on the cache. That is, we'd impose a time out where no query, regardless of how popular it is, can sit in the cache for more than x minutes.
This will ensure that all data is periodically refreshed.
